# llm-local-assistant
Streamlit-based web application for a local AI assistant using Llama 3/3.1 8B models. Features function calling, web search, and summarization capabilities. Expandable to multi-task operations including predictions and image generation. Prioritizes data privacy through offline, local model deployment.

## Acknowledgements
This project is based on work by Adam ≈Åucek, available at (https://github.com/ALucek/llama3-websearch-agent). 
The original work is licensed under the MIT License.
